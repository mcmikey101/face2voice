{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\projects\\face2voice\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from face2voice.models.SpeakerEncoder import SpeakerEncoder\n",
    "from openvoice.api import ToneColorConverter\n",
    "import torch\n",
    "import numpy as np\n",
    "from face2voice.models.Face2Voice import Face2VoiceModel\n",
    "from face2voice.models.FaceEncoder import FaceEncoder\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from face2voice.losses.compound_loss import CompoundLoss\n",
    "from face2voice.models.TTSModel import TTSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing base speech\n",
      "Base audio generated: outputs/pipertts_ru_test.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'outputs/pipertts_ru_test.wav'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts_model = TTSModel(language=\"ru\")\n",
    "tts_model.synthesize(text=\"Радуга, атмосферное, оптическое и метеорологическое явление, наблюдаемое при освещении ярким источником света множества водяных капель.\",\n",
    "                     output_path=\"outputs/pipertts_ru_test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\projects\\face2voice\\.venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'face2voice\\checkpoints\\tone_conv\\checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n"
     ]
    }
   ],
   "source": [
    "speaker_encoder = SpeakerEncoder(config_path=r'face2voice\\checkpoints\\tone_conv\\config.json', ckpt_path=r'face2voice\\checkpoints\\tone_conv\\checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_encoder = FaceEncoder()\n",
    "state_dict = torch.load(r\"face2voice\\checkpoints\\face_encoder\\facenet_checkpoint.pth\")\n",
    "face_encoder.load_state_dict(state_dict=state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face2voice = Face2VoiceModel(face_encoder=face_encoder, speaker_encoder=speaker_encoder)\n",
    "st_dict = torch.load(r\"face2voice\\checkpoints\\f2v\\face2voice_ckpt.pth\", weights_only=False)\n",
    "face2voice.load_state_dict(st_dict[\"model_state_dict\"])\n",
    "face2voice.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_transform = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVoice version: v1\n",
      "[(0.0, 8.904875)]\n",
      "after vad: dur = 8.903990929705216\n",
      "OpenVoice version: v1\n",
      "[(0.0, 8.904875)]\n",
      "after vad: dur = 8.903990929705216\n",
      "OpenVoice version: v1\n",
      "[(0.0, 8.904875)]\n",
      "after vad: dur = 8.903990929705216\n",
      "OpenVoice version: v1\n",
      "[(0.0, 8.904875)]\n",
      "after vad: dur = 8.903990929705216\n",
      "OpenVoice version: v1\n",
      "[(0.0, 8.904875)]\n",
      "after vad: dur = 8.903990929705216\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for pic in os.listdir(r\"C:\\Users\\user\\Desktop\\projects\\face2voice\\resources\"):\n",
    "    if \".jpg\" in pic:\n",
    "        speaker = pic.replace(\".jpg\", \"\")\n",
    "        img = Image.open(f\"resources\\{pic}\").convert(\"RGB\")\n",
    "        img = face_transform(img).unsqueeze(0)\n",
    "        tgt_emb = face2voice(img)\n",
    "        src_emb = face2voice.speaker_encoder.encode_single(audio=\"outputs\\pipertts_ru_test.wav\", input=\"audio\", return_numpy=False)\n",
    "        tgt_emb = tgt_emb.detach().clone().requires_grad_(True).reshape(1, -1, 1)\n",
    "        src_emb = src_emb.detach().clone().requires_grad_(True).transpose(1, 2).squeeze(0).reshape(1, -1, 1)\n",
    "        face2voice.speaker_encoder.tone_color_converter.convert(audio_src_path=\"outputs\\pipertts_ru_test.wav\", src_se=src_emb, tgt_se=tgt_emb, output_path=f\"outputs/{speaker}_ru_clone.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
