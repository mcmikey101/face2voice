# ArcFace Encoder Configuration
# This file controls all aspects of the ArcFace face encoder

# ==================== Model Architecture ====================
model:
  # Backbone architecture
  # Options: resnet18, resnet34, resnet50, resnet100 (requires custom implementation)
  backbone: resnet50
  
  # Dimension of face embeddings
  embedding_dim: 512
  
  # Input image size (width and height)
  # ArcFace typically uses 112x112
  input_size: 112
  
  # Dropout rate in embedding head (0.0 = no dropout)
  dropout: 0.0
  
  # Use batch normalization in embedding head
  use_batchnorm: true


# ==================== Pretrained Weights ====================
pretrained:
  # Whether to load pretrained weights
  enabled: true
  
  # Path to pretrained weights file
  # Download from: https://github.com/deepinsight/insightface
  # Or use your own trained weights
  weights_path: pretrained/arcface_resnet50.pth
  
  # Strict loading (set false to allow missing keys)
  strict_load: true


# ==================== Training Configuration ====================
training:
  # Freeze the entire backbone (only train embedding head)
  # Set to false if you want to fine-tune the backbone
  freeze_backbone: true
  
  # Freeze batch normalization layers
  # Recommended when using pretrained models
  freeze_bn: true
  
  # Specific layers to make trainable (even if freeze_backbone is true)
  # Examples: ['layer4', 'layer3', 'fc']
  # Empty list means only embedding_head is trainable (if freeze_backbone=true)
  trainable_layers: []
  
  # Learning rate for trainable parameters
  learning_rate: 0.0001
  
  # Weight decay (L2 regularization)
  weight_decay: 0.0005
  
  # Optimizer settings
  optimizer:
    type: adamw  # Options: adam, adamw, sgd
    momentum: 0.9  # Only for SGD
    betas: [0.9, 0.999]  # Only for Adam/AdamW
  
  # Learning rate scheduler
  scheduler:
    enabled: true
    type: cosine  # Options: cosine, step, plateau, exponential
    
    # Cosine annealing settings
    T_max: 50  # Number of epochs for full cosine cycle
    eta_min: 0.000001  # Minimum learning rate
    
    # Step scheduler settings
    step_size: 10  # Decay every N epochs
    gamma: 0.1  # Decay factor
    
    # Plateau scheduler settings
    patience: 5  # Number of epochs with no improvement
    factor: 0.5  # Factor to reduce LR


# ==================== Data Augmentation ====================
augmentation:
  # Enable augmentation during training
  enabled: true
  
  # Random horizontal flip
  horizontal_flip: true
  horizontal_flip_prob: 0.5
  
  # Color jittering
  color_jitter: false
  brightness: 0.2
  contrast: 0.2
  saturation: 0.2
  hue: 0.1
  
  # Random rotation
  rotation: false
  rotation_degrees: 15
  
  # Random crop and resize
  random_crop: false
  crop_scale: [0.8, 1.0]
  
  # Normalization (ImageNet stats)
  normalize:
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]


# ==================== Fine-tuning Strategies ====================
# Experiment with different fine-tuning approaches

# Strategy 1: Frozen backbone (default)
# freeze_backbone: true
# trainable_layers: []
# learning_rate: 0.0001

# Strategy 2: Fine-tune last layer
# freeze_backbone: true
# trainable_layers: ['layer4']
# learning_rate: 0.00001

# Strategy 3: Full fine-tuning with low LR
# freeze_backbone: false
# trainable_layers: []
# learning_rate: 0.00001

# Strategy 4: Gradual unfreezing
# Start with freeze_backbone: true
# After N epochs, set freeze_backbone: false
# Reduce learning rate accordingly


# ==================== Experimental Settings ====================
experiment:
  # Experiment name for logging
  name: arcface_baseline
  
  # Random seed for reproducibility
  seed: 42
  
  # Device
  device: cuda  # Options: cuda, cpu, cuda:0, cuda:1, etc.
  
  # Mixed precision training
  use_amp: true
  
  # Gradient clipping
  gradient_clip:
    enabled: false
    max_norm: 1.0


# ==================== Logging and Checkpointing ====================
logging:
  # Log directory
  log_dir: logs/arcface
  
  # Tensorboard logging
  use_tensorboard: true
  
  # Wandb logging
  use_wandb: false
  wandb_project: face2voice
  wandb_entity: your_username
  
  # How often to log (in steps)
  log_interval: 100
  
  # How often to validate (in epochs)
  val_interval: 1


checkpointing:
  # Checkpoint directory
  checkpoint_dir: checkpoints/arcface
  
  # Save checkpoint every N epochs
  save_interval: 5
  
  # Keep only last N checkpoints
  keep_last_n: 3
  
  # Save best model based on validation metric
  save_best: true
  best_metric: val_loss  # Options: val_loss, val_accuracy, etc.


# ==================== Evaluation ====================
evaluation:
  # Batch size for evaluation
  batch_size: 32
  
  # L2 normalize embeddings before evaluation
  normalize_embeddings: true
  
  # Metrics to compute
  metrics:
    - cosine_similarity
    - euclidean_distance
    - face_verification_accuracy